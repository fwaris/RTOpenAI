namespace rec RTOpenAI.Events

open System
open System.Text.Json
open System.Text.Json.Serialization

//generated by o1 from openai realtime api docs scraped from website
//default static properties added by github copilot
//default values added manually

(* Codegen notes
- o1 largely got all objects correct (almost 450 lines of code with no compile errors)
- However several corrections were needed to make event definitions correct as per API documentation
- Strongly typed properties and json converters added manually
- o1 missed response.audio_... and later events (maybe due to token limit set in the codegen api call)

- Update: Manually updated to match OpenAI realtime API version change
*)

module Utils =
    
    let newId() = 
        Guid.NewGuid().ToByteArray() 
        |> Convert.ToBase64String 
        |> Seq.takeWhile (fun c -> c <> '=') 
        |> Seq.collect (function '/' -> ['_';'_'] | '\\' -> ['-';'-'] | '+' -> ['_';'-'] | c -> [c])
        |> Seq.toArray 
        |> String

// Shared Types
type InputAudioTranscription =
    {
        model: string
    }
    static member Default = { model = "gpt-4o-mini-transcribe"}

type TurnDetection =
    {
        ``type``: string option
        threshold: float option
        prefix_padding_ms: int option
        silence_duration_ms: int option
    }
    static member Default = { 
        ``type`` = Some "server_vad" // None to turn off
        threshold = Some 0.5
        prefix_padding_ms = Some 300  // How much audio to include in the audio stream before the speech starts.
        silence_duration_ms = Some 200 //// How long to wait to mark the speech as stopped.
    }
    
[<JsonFSharpConverter(SkippableOptionFields=SkippableOptionFields.Always)>]
type JsDesc = {description : string option}

[<JsonFSharpConverter(SkippableOptionFields=SkippableOptionFields.Always)>]
type JsString = {description : string option; enum : string list option}

[<JsonFSharpConverter(SkippableOptionFields=SkippableOptionFields.Always)>]
type JsObj = 
    {
        description: string option
        properties: Map<string, JsProperty>
        required: string list
        additionalProperties:bool
    }

and [<JsonFSharpConverter(SkippableOptionFields=SkippableOptionFields.Always)>]
    JsArray = {description: string option; items: JsProperty}

and [<RequireQualifiedAccess>]     
    JsProperty =  
    | [<JsonName "integer">] Integer of JsDesc
    | [<JsonName "number">] Number of JsDesc
    | [<JsonName "string">] String of JsString
    | [<JsonName "boolean">] Boolean of JsDesc
    | [<JsonName "array">] Array of JsArray
    | [<JsonName "object">] Object of JsObj

type Parameters =
    {
        ``type``: string
        properties: Map<string, JsProperty>
        required: string list
        additionalProperties : bool
    }
    static member Default = { ``type`` = "object"; properties = Map.empty; required = []; additionalProperties = false }

    
type Tool =
    {
        name: string
        description: string
        parameters: Parameters
        ``type`` : string
    }
    static member Default = { ``type``= "function"; name = ""; description = ""; parameters = Parameters.Default}

type Client_Secret = {
     expires_at : int64
     value : string
}

[<JsonFSharpConverter>]
type Transcription = {
    language : string
    model : string
    prompt : string option
}

[<JsonFSharpConverter(
    BaseUnionEncoding = JsonUnionEncoding.InternalTag,
    UnionTagName = "type",
    UnionUnwrapRecordCases = true
)>]

//voice activity detection
type VAD = 
    | [<JsonName "server_vad">] Server_Vad of
                    {|create_response     : bool
                      idle_timeout_ms     : Skippable<int option>
                      interrupt_response  : bool
                      prefix_padding_ms   : int
                      silence_duration_ms : int
                      threshold           : float                      
                    |}
    | [<JsonName "semantic_vad">] Semantic_Vad of
                      {| create_response    : bool
                         eagerness          : string //high,medium,low, auto
                         interrupt_response : bool
                      |}
                      
[<JsonFSharpConverter(
    BaseUnionEncoding = JsonUnionEncoding.InternalTag,
    UnionTagName = "type",
    UnionUnwrapRecordCases = true
)>]

[<RequireQualifiedAccess>]
type AudioFormat =
    | [<JsonName("audio/pcm")>] PCM of {|rate:int|} //24000
    | [<JsonName("audio/pcmu")>] PCMU
    | [<JsonName("audio/pcma")>] PCMA 
   
type NoiseReduction = {``type`` : string}

[<JsonFSharpConverter>]
type AudioInput = {
    format : AudioFormat
    noise_reduction : Skippable<NoiseReduction option>
    transcription : Skippable<Transcription option>
    turn_detection : Skippable<VAD option>
}
    with
    static member Default =
        {
            noise_reduction = Skip
            format = AudioFormat.PCM {|rate=24000|}                                             
            transcription = Skip
            turn_detection = Skip
        }                                

[<JsonFSharpConverter>]
type AudioOutput = {
    format : AudioFormat
    speed : Skippable<float option>
    voice : string
}
    with
    static member Default =
        {
            format = AudioFormat.PCM {|rate=24000|}
            speed = Include (Some 1.0)
            voice = "alloy"
        }
        
[<JsonFSharpConverter>]
type Audio = {
    input: Skippable<AudioInput>
    output : Skippable<AudioOutput> //don't need output for 'transcription' sessions
}
    with
    static member Default =
        {
            input = Skip
            output = Skip
        }
        
type Prompt = {
        id : string
        variables : Map<string,string>
        version : string
    }
    
[<JsonFSharpConverter(BaseUnionEncoding = JsonUnionEncoding.UnwrapRecordCases)>]
type Tracing =
    | Auto
    | Configuration of {|group_id:string; metadata:JsonElement; workflow_name:string |}
    
type TokenLimits = {
    post_instructions : int
}

type OutputTokensTypeConverter() =
    inherit JsonConverter<OutputTokens>()

    override _.Read(reader, _, _) =
        let value = reader.GetString()
        match value with
        | "inf" -> OutputTokens.Inf
        | x     -> OutputTokens.Value (int x)    
    override _.Write(writer, value, _) =
        match value with
        | Inf -> writer.WriteStringValue("inf") 
        | Value v -> writer.WriteNumberValue(v)
and [<JsonConverter(typeof<OutputTokensTypeConverter>)>]
    OutputTokens =
    | Inf
    | Value of int

[<JsonFSharpConverter(BaseUnionEncoding = JsonUnionEncoding.UnwrapRecordCases)>]
type Truncation =
    | [<JsonName "auto">] Auto
    | [<JsonName "disabled">] Disabled
    | Truncation of {|retention_ratio:float; ``type`` : string; token_limits : TokenLimits option|}

[<JsonFSharpConverter>]
type Session =
    {
        ``type`` : Skippable<string> 
        id: Skippable<string>
        ``object`` : Skippable<string>        
        model: string option
        audio : Skippable<Audio>
        ``include`` : Skippable<string list>
        output_modalities: Skippable<string list>
        instructions: string option
        prompt : Skippable<Prompt option>
        tool_choice: Skippable<string>
        tools: Skippable<Tool list>
        tracing : Skippable<Tracing option>
        truncation : Skippable<Truncation option>
        max_output_tokens : Skippable<OutputTokens option> 
        client_secret : Skippable<Client_Secret option>
        value : Skippable<string>
        expires_at : Skippable<int>
    }
    static member Default = 
        {
            ``type`` = Include "realtime"
            id = Skip
            ``object`` = Skip
            model = None
            audio = Skip
            ``include`` = Include []
            output_modalities = Skip
            instructions = None
            prompt = Skip
            tool_choice = Skip //How the model chooses tools. Options are "auto", "none", "required", or specify a function.
            tools = Skip
            tracing = Skip
            truncation = Skip
            client_secret = Skip
            max_output_tokens = Skip
            value = Skip
            expires_at = Skip
        }

///Overload of client and server versions of Response
[<JsonFSharpConverter>]
type Response =
    {
        
        audio : Skippable<Audio>
        conversation : Skippable<string>
        conversation_id : Skippable<string>
        id : Skippable<string>
        input : Skippable<ConversationItem list>
        output : Skippable<ConversationItem list>
        instructions: Skippable<string>
        max_output_tokens : Skippable<OutputTokens option> 
        metadata : Skippable<Map<string,string> option>
        output_modalities: Skippable<string list>
        prompt : Skippable<Prompt option>
        tool_choice: Skippable<string>
        tools: Skippable<Tool list>
        object : Skippable<string>
        status : Skippable<string>
        status_details : Skippable<StatusDetails option>
        usage : Skippable<Usage option>
        
    }
    static member Default : Response = 
        {
            audio = Skip
            id = Skip
            conversation = Skip
            conversation_id = Skip
            input = Skip
            output = Skip
            instructions = Skip
            max_output_tokens = Skip 
            metadata = Skip
            output_modalities = Skip
            prompt = Skip
            tool_choice = Skip
            tools = Skip
            object = Skip
            status = Skip
            status_details = Skip
            usage = Skip
        }


type ErrorDetail =
    {
        ``type``: string
        code: string
        message: string
        param: Skippable<string option>
        event_id: Skippable<string option>
    }
    static member Default = { ``type`` = ""; code = ""; message = ""; param = Skip; event_id = Skip }
    
type Usage = {
    ``type`` : Skippable<string>
    total_tokens : int
    input_tokens : int
    output_tokens : int
    input_token_details : {|text_tokens:int; audio_tokens:int|}
}
    with static member Default = { total_tokens = 0; input_tokens = 0; output_tokens = 0; input_token_details ={|text_tokens=0; audio_tokens=0|}; ``type`` = Include "tokens"}

/// Send this event to update the session’s default configuration.
[<JsonFSharpConverter>]
type SessionUpdate =
    {
        event_id: string
        ``type``: string  // "session.update"
        session: Session
    }
    static member Default = { event_id = ""; ``type`` = "session.update"; session = Session.Default }

///Send this event to append audio bytes to the input audio buffer.
type InputAudioBufferAppend =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.append"
        audio: string  // Base64 encoded audio data
    }
    static member Default = { event_id = ""; ``type`` = "input_audio_buffer.append"; audio = "" }

///Send this event to commit audio bytes to a user message.
type InputAudioBufferCommit =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.commit"
    }
    static member Default = { event_id = ""; ``type`` = "input_audio_buffer.commit" }

///Send this event to clear the audio bytes in the buffer.
type InputAudioBufferClear =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.clear"
    }
    static member Default = { event_id = ""; ``type`` = "input_audio_buffer.clear" }

///Send this event when adding an item to the conversation.
type ConversationItemCreate =
    {
        event_id: string
        ``type``: string  // "conversation.item.create"
        previous_item_id: Skippable<string>
        item: ConversationItem
    }
    static member Default = { event_id = ""
                              ``type`` = "conversation.item.create"
                              previous_item_id = Skip
                              item = ConversationItem.Message ContentMessage.Default
                              }

///Send this event when adding an item to the conversation.
type ConversationItemRetrieve =
    {
        event_id: string
        item_id : string
        ``type``: string  // "conversation.item.create"
    }
    static member Default = { event_id = ""; ``type`` = "conversation.item.retrieve"; item_id = ""}


///Send this event when you want to truncate a previous assistant message’s audio.
type ConversationItemTruncate =
    {
        event_id: string
        ``type``: string  // "conversation.item.truncate"
        item_id: string
        content_index: int
        audio_end_ms: int
    }
    static member Default = { event_id = ""; ``type`` = "conversation.item.truncate"; item_id = ""; content_index = 0; audio_end_ms = 0 }

type OutputAudioBufferClear = {
    event_id : string
    response_id : string
    ``type`` : string
}
with static member Default = {event_id=""; ``type``="response.cancel"; response_id=""}

///Send this event when you want to remove any item from the conversation history.
type ConversationItemDelete =
    {
        event_id: string
        ``type``: string  // "conversation.item.delete"
        item_id: string
    }
    static member Default = { event_id = ""; ``type`` = "conversation.item.delete"; item_id = "" }

///Send this event to trigger a response generation.
type ResponseCreate =
    {
        event_id: string
        ``type``: string  // "response.create"
        response: Skippable<Response>
    }
    static member Default = { event_id = ""; ``type`` = "response.create"; response = Skip }

///Send this event to cancel an in-progress response.
type ResponseCancel =
    {
        event_id: string
        ``type``: string  // "response.cancel"
    }
    static member Default = { event_id = ""; ``type`` = "response.cancel" }

[<JsonFSharpConverter>]
type MessageAudioContent =
    {
        audio: Skippable<string>
        transcript: Skippable<string>
        format: Skippable<JsonElement>
    }

[<JsonFSharpConverter>]
type MessageTextContent =
    {
        text: Skippable<string>
        annotations: Skippable<JsonElement>
    }

type MessageContent =
    | [<JsonName("input_audio")>] Input_audio of {|audio:Skippable<string>; transcript:string|}
    | [<JsonName("input_text")>] Input_text of {|text:string|}
    | [<JsonName("input_image")>] Input_image of {|image_url:string; detail:string|}
    | [<JsonName("output_audio")>] Output_audio of MessageAudioContent
    | [<JsonName("audio")>] Audio of MessageAudioContent
    | [<JsonName("text")>] Text of MessageTextContent
    | [<JsonName("output_text")>] Output_text of MessageTextContent
        
type ContentMessage = {
    content : MessageContent List
    role : string
    id : Skippable<string>
    object : Skippable<string>
    status : string
}
with static member Default : ContentMessage = {
            role = "user"
            id = Skip
            object = Skip
            status = "completed"
            content = [Input_text {|text="hello"|}]
    }

type ContentFunctionCall = {
    name : string
    arguments : string
    call_id : string
    id : string
    object : Skippable<string>
    status : string
}

type ContentFunctionCallOutput = {
    call_id : string
    output : string
    id : string
    object : Skippable<string>
    status : string
} with static member Create callId output = {
        call_id = callId
        output = output
        id = Utils.newId()
        object = Skip
        status = "completed"
}

type ContentMcpApprovalResponse = {
    approval_request_id : string
    approve : bool
    id : string
    reason : string
}

type ContentMcpApprovalRequest = {
    arguments : string
    id : string
    name : string
    server_label : string
}

type McpTool = {
    input_schema : JsonElement
    name : string
    annotations : JsonElement
    description : string
}

type ContentMcpListTools = {
    server_label : string
    tools : McpTool list
    id : string
}

type ContentMcpToolCall = {
    arguments : string
    id : string
    name : string
    server_label : string
    approval_request_id : string
    output : string
    error : {|code:int; message:string; ``type``:string|}
}

[<JsonFSharpConverter(
    BaseUnionEncoding = JsonUnionEncoding.InternalTag,
    UnionTagName = "type",
    UnionUnwrapRecordCases = true
)>]
type ConversationItem = 
    | [<JsonName "message">] Message of ContentMessage
    | [<JsonName "function_call">] Function_call of ContentFunctionCall
    | [<JsonName "function_call_output">] Function_call_output of ContentFunctionCallOutput
    | [<JsonName "mcp_approval_response">] Mcp_approval_response of ContentMcpApprovalResponse
    | [<JsonName "mcp_call">] Mcp_call of ContentMcpToolCall
    | [<JsonName "mcp_list_tools">] Mcp_list_tools of ContentMcpListTools    
    | [<JsonName "mcp_approval_request">] Mcp_approval_request of ContentMcpApprovalRequest
    

//Error event
type Error =
    {
        event_id: string
        ``type``: string  // "error"
        error: ErrorDetail
    }

///Returned when a session is created. Emitted automatically when a new connection is established.
type SessionCreated =
    {
        event_id: string
        ``type``: string  // "session.created"
        session: Session
    }

///Returned when a session is updated.
type SessionUpdated =
    {
        event_id: string
        ``type``: string  // "session.updated"
        session: Session
    }


///Overloaded: Sent by the server when an Item is added|done|retrieved to the default Conversation
type ConversationItemEvent =
    {
        event_id: string
        item : ConversationItem
        ``type``: string  // "conversation.item.[added|done|retrieved]"
        previous_item_id : Skippable<string option>
    }
   
type LogProbs = {bytes:int list; logprob:float; token:string}

///Returned when input audio transcription is enabled and a transcription succeeds.
type ConversationItemInputAudioTranscriptionCompleted =
    {
        event_id: string
        ``type``: string  // "conversation.item.input_audio_transcription.completed"
        item_id: string
        content_index: int
        transcript: string
        usage : Usage
        logprobs : Skippable<LogProbs list option> 
    }
    
type ConversationItemInputAudioTranscriptionDelta =
    {
        content_index: int
        delta : string
        event_id: string
        item_id: string
        logprobs : Skippable<LogProbs list option> 
        ``type``: string  // "conversation.item.input_audio_transcription.delta"
    }
    
type ConversationItemInputAudioTranscriptionSegment =
    {
        content_index: int
        ``end`` : float
        event_id: string
        id : string //segment identifier
        item_id: string
        speaker : string
        start : float
        text  : string         
        ``type``: string  // "conversation.item.input_audio_transcription.segment"
    }

///Returned when input audio transcription is configured, and a transcription request for a user message failed.
type ConversationItemInputAudioTranscriptionFailed =
    {
        content_index: int
        error: ErrorDetail
        event_id: string
        item_id: string
        ``type``: string  // "conversation.item.input_audio_transcription.failed"
    }

///Returned when an earlier assistant audio message item is truncated by the client.
type ConversationItemTruncated =
    {
        event_id: string
        ``type``: string  // "conversation.item.truncated"
        item_id: string
        content_index: int
        audio_end_ms: int
    }

///Returned when an item in the conversation is deleted.
type ConversationItemDeleted =
    {
        event_id: string
        ``type``: string  // "conversation.item.deleted"
        item_id: string
    }

///Returned when an input audio buffer is committed, either by the client or automatically in server VAD mode.
type InputAudioBufferCommitted =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.committed"
        previous_item_id: string option
        item_id: string
    }
    
///SIP Only: Returned when an DTMF event is received. A DTMF event is a message that represents a telephone keypad press (0–9, *, #, A–D).
type InputAudioBufferDtmfEventReceived =
    {
        event : string
        received_at : int
        item_id: Skippable<string option>
    }

///Returned when the input audio buffer is cleared by the client.
type InputAudioBufferCleared =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.cleared"
    }

///Returned in server turn detection mode when speech is detected.
type InputAudioBufferSpeechStarted =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.speech_started"
        audio_start_ms: int
        item_id: string
    }

///Returned in server turn detection mode when speech stops.
type InputAudioBufferSpeechStopped =
    {
        event_id: string
        ``type``: string  // "input_audio_buffer.speech_stopped"
        audio_end_ms: int
        item_id: string
    }

///Returned when the Server VAD timeout is triggered for the input audio buffer. This is configured with idle_timeout_ms in the turn_detection settings of the session, and it indicates that there hasn't been any speech detected for the configured duration.
type InputAudioBufferTimeoutTriggered =
    {
        audio_end_ms: int
        audio_start_ms : int
        event_id: string
        item_id: string
        ``type``: string  // "input_audio_buffer.timeout_triggered"
    }
    
///WebRTC/SIP Only: Emitted when the server begins streaming audio to the client. This event is emitted after an audio content part has been added (response.content_part.added) to the response. 
type OutputAudioBufferStarted =
    {
        event_id: string
        response_id: string
        ``type``: string  // "output_audio_buffer.[started|stopped]"
    }    

type OutputAudioBufferStopped = OutputAudioBufferStarted
type OutputAudioBufferCleared = OutputAudioBufferStarted

///Returned when a new Response is created. The first event of response creation, where the response is in an initial state of "in_progress".
type ResponseCreated =
    {
        event_id: string
        ``type``: string  // "response.created"
        response: Response
    }

///Returned when a Response is done streaming. Always emitted, no matter the final state.
type ResponseDone =
    {
        event_id: string
        ``type``: string  // "response.done"
        response: Response
    }

///Returned when a new Item is created during response generation.
///Also when an Item is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseOutputItem =
    {
        event_id: string
        item: ConversationItem
        output_index: int
        response_id: string
        ``type``: string  // "response.output_item.[added|done]"
    }

///Returned when a new content part is added to an assistant message item during response generation.
///Also when a content part is done streaming in an assistant message item. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseContentPart =
    {
        content_index: int
        event_id: string
        item_id: string
        output_index: int
        part: ContentPart
        response_id: string
        ``type``: string  // "response.content_part.[added|done]"
    }

///Returned when the text value of a "text" content part is updated.
type ResponseOutputTextDelta =
    {
        content_index: int
        delta: string
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string  // "response.text.delta"
    }

///Returned when the text value of a "text" content part is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseOutputTextDone =
    {
        content_index: int
        event_id: string
        response_id: string
        output_index: int
        item_id: string
        text: string
        ``type``: string  // "response.text.done"
    }

///Returned when the model-generated transcription of audio output is updated.
type ResponseOutputAudioTranscriptDelta =
    {
        content_index: int
        delta: string
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string  // "response.text.done"
    }

///Returned when the model-generated transcription of audio output is done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseOutputAudioTranscriptDone =
    {
        content_index: int
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        transcript: string
        ``type``: string  // "response.text.done"
    }


///Returned when the model-generated function call arguments are done streaming. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseFunctionCallArgumentsDone = 
    {
        arguments: string
        call_id: string
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string
    }

///Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseFunctionCallArgumentsDelta = 
    {
        call_id: string
        delta: string
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string
    }

///Returned when the model-generated audio is updated.
type ResponseOutputAudioDelta = 
    {
        content_index: int
        delta: string
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string //response.output_audio.delta
    }

///Returned when the model-generated audio is done. Also emitted when a Response is interrupted, incomplete, or cancelled.
type ResponseOutputAudioDone = 
    {
        content_index: int
        event_id: string
        item_id: string
        output_index: int
        response_id: string
        ``type``: string //response.output_audio.done
    }
 
type ResponseMcpCallArgumentsDelta =
    {
        delta : string
        event_id : string
        item_id : string
        obfuscation : Skippable<string option>
        output_index : int
        response_id : string
        ``type`` : string
    }
    
type ResponseMcpCallArgumentsDone =
    {
        arguments : string
        event_id : string
        item_id : string
        output_index : int
        response_id : string
        ``type`` : string
    }
    
//overloaded for multiple mcp events
type ResponseMcp =
    {    
        event_id : string
        item_id : string
        output_index : Skippable<int option>
        ``type`` : string //mcp_call.[in_progress|completed|failed]
                          //mcp_list_tools.[in_progress|completed|failed]
    }
    
type RateLimit =
    {
        limit : int
        name : string
        remaining : int
        reset_seconds : float
    }
 
///Emitted after every "response.done" event to indicate the updated rate limits.
type RateLimitsUpdated =
    {
        event_id: string
        rate_limits: RateLimit list
        ``type``: string  // "rate_limits.updated"
    }

type Conversation =
    {
        id: string
        ``object``: string
    }
    
type StatusError =
    {
        ``type`` : string //usually "server_error"
        code : string option
    }
    
type StatusDetails =
        {
            ``type`` : string
            error : Skippable<StatusError>
            reason : string
        }
        

///Returned when a new content part is added to an assistant message item during response generation.
type ContentPart =
    {
        audio : Skippable<string option>
        text: Skippable<string option>
        transcript: Skippable<string option>
        ``type``: string //[audio | text ]
    }


[<RequireQualifiedAccess>]
type ServerEvent =
    | Error of Error
    //session
    | SessionCreated of SessionCreated
    | SessionUpdated of SessionUpdated
    //conversation item
    | ConversationItemAdded of ConversationItemEvent
    | ConversationItemDone of ConversationItemEvent
    | ConversationItemRetrieved of ConversationItemEvent
    | ConversationItemTruncated of ConversationItemTruncated
    | ConversationItemDeleted of ConversationItemDeleted
    //conversation item input audio transcription
    | ConversationItemInputAudioTranscriptionCompleted of ConversationItemInputAudioTranscriptionCompleted
    | ConversationItemInputAudioTranscriptionDelta of ConversationItemInputAudioTranscriptionDelta
    | ConversationItemInputAudioTranscriptionSegment of ConversationItemInputAudioTranscriptionSegment
    | ConversationItemInputAudioTranscriptionFailed of ConversationItemInputAudioTranscriptionFailed
    //input audio buffer
    | InputAudioBufferCommitted of InputAudioBufferCommitted
    | InputAudioBufferDtmfEventReceived of InputAudioBufferDtmfEventReceived
    | InputAudioBufferCleared of InputAudioBufferCleared
    | InputAudioBufferSpeechStarted of InputAudioBufferSpeechStarted
    | InputAudioBufferSpeechStopped of InputAudioBufferSpeechStopped
    | InputAudioBufferTimeoutTriggered of InputAudioBufferTimeoutTriggered
    //output audio buffer
    | OutputAudioBufferStarted of OutputAudioBufferStarted
    | OutputAudioBufferStopped of OutputAudioBufferStopped
    | OutputAudioBufferCleared of OutputAudioBufferCleared
    //response
    | ResponseCreated of ResponseCreated
    | ResponseDone of ResponseDone
    | ResponseOutputItemAdded of ResponseOutputItem
    | ResponseOutputItemDone of ResponseOutputItem
    | ResponseContentPartAdded of ResponseContentPart
    | ResponseContentPartDone of ResponseContentPart
    | ResponseOutputTextDelta of ResponseOutputTextDelta
    | ResponseOutputTextDone of ResponseOutputTextDone
    | ResponseOutputAudioTranscriptDelta of ResponseOutputAudioTranscriptDelta
    | ResponseOutputAudioTranscriptDone of ResponseOutputAudioTranscriptDone
    | ResponseOutputAudioDelta of ResponseOutputAudioDelta
    | ResponseOutputAudioDone of ResponseOutputAudioDone
    | ResponseFunctionCallArgumentsDelta of ResponseFunctionCallArgumentsDelta
    | ResponseFunctionCallArgumentsDone of ResponseFunctionCallArgumentsDone
    | ResponseMcpCallArgumentsDelta of ResponseMcpCallArgumentsDelta
    | ResponseMcpCallArgumentsDone of ResponseMcpCallArgumentsDone
    | ResponseMcpCallInProgress of ResponseMcp
    | ResponseMcpCallCompleted of ResponseMcp
    | ResponseMcpCallFailed of ResponseMcp
    | ResponseMcpListToolsInProgress of ResponseMcp
    | ResponseMcpListToolsCompleted of ResponseMcp
    | ResponseMcpListToolsFailed of ResponseMcp

    //others
    | RateLimitsUpdated of RateLimitsUpdated
    ///No predefined type can be mapped to this event
    | UnknownEvent of string * JsonDocument
    ///Error occured while trying to parse the event. Usually it's a serialization error.
    | EventHandlingError of string*string*JsonDocument

[<RequireQualifiedAccess>]
type ClientEvent =
    | SessionUpdate of SessionUpdate
    | InputAudioBufferAppend of InputAudioBufferAppend
    | InputAudioBufferCommit of InputAudioBufferCommit
    | InputAudioBufferClear of InputAudioBufferClear
    | ConversationItemCreate of ConversationItemCreate
    | ConversationItemRetrieve of ConversationItemRetrieve
    | ConversationItemTruncate of ConversationItemTruncate
    | ConversationItemDelete of ConversationItemDelete
    | ResponseCreate of ResponseCreate
    | ResponseCancel of ResponseCancel
    | OutputAudioBufferClear of OutputAudioBufferClear

